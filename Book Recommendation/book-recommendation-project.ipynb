{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goodbooks-10k Recommendation Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "* I will be experimenting with three popular techniques that are commonly used in the Recommendation System world. These include:\n",
    "\n",
    "    **1. Weighted-Scoring/Popularity-Based:**\n",
    "\n",
    "    All books receive a score from 1 to 5 that takes into account their average rating and number of ratings given. Books that have a higher score are deemed more \"popular\" and are more likely to be recommended to the user.\n",
    "\n",
    "    **2. Content-Based Filtering:**\n",
    "\n",
    "    The system heavily relies on item attributes such as book summary, author, tags, date published, etc. to recommend books similar to ones the user has read already. \n",
    "\n",
    "    **3. Collaborative Filtering:**\n",
    "\n",
    "    This method is based on the belief that people like things that are similar to what they already like and things that people who are similar to them also like. There are a couple types of collaborative filtering and methods to go about implementing it, but we will delve into it later on.\n",
    "    \n",
    "\n",
    "### Table of Contents:\n",
    "#### 1. Data Collection\n",
    "#### 2. Data Cleaning\n",
    "#### 3. Exploratory Data Analysis\n",
    "#### 4. Weighted-Scoring/Popularity-Based Filtering\n",
    "#### 5. Content-Based Filtering\n",
    "#### 6. Collaborative Filtering\n",
    "#### 7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import accuracy\n",
    "\n",
    "import random                                                              \n",
    "                                                                           \n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "CSS = \"\"\"\n",
    ".output {\n",
    "    flex-direction: row;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "HTML('<style>{}</style>'.format(CSS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "pd.options.display.max_colwidth = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "book_tags = pd.read_csv(r'../input/goodbooks-10k/book_tags.csv')\n",
    "ratings = pd.read_csv(r'../input/goodbooks-10k/ratings.csv')\n",
    "books = pd.read_csv(r'../input/goodbooks-10k/books.csv')\n",
    "tags = pd.read_csv(r'../input/goodbooks-10k/tags.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 books\n",
    "\n",
    "<mark>books</mark> contains 10,000 books and 23 columns listing their attributes.\n",
    "\n",
    "- Replace *book_id* to *goodreads_book_id* to make joining tables easier \n",
    "- Replace *id* to *book_id* \n",
    "- Filter out irrelevant columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(books.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(books.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out columns \n",
    "books_cleaned = books[['id','book_id','title','average_rating','work_ratings_count','original_publication_year']].rename(columns={'book_id' : 'goodreads_book_id', 'id' : 'book_id'})\n",
    "display(books_cleaned);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 *tags* and *book_tags*\n",
    "\n",
    "Every book is given multiple tags set by various users. These tags could be the author, genre, or any other aspect of the book. The table ***tags*** maps each tag_id to its string representation and the table ***book_tags*** lists every book, their tags, and tag counts. These tables are key to implementing our content-based filtering algorithm.\n",
    "\n",
    "**Cleaning *book_tags* and *tags***\n",
    "\n",
    "- Combine the tables on *tag_id*\n",
    "- Filter top 30 tags per book (ranked by number of times book was tagged by tag) to save space\n",
    "- Add a column containing the book title \n",
    "\n",
    "**In order to make sure TfidVectorizer works properly, we have to clean the tag names**\n",
    "\n",
    "- Standardize letters to lowercase \n",
    "- Replace all punctuation with spaces \n",
    "- Trim white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the raw book_tags and tags tables\n",
    "display(book_tags)\n",
    "display(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add book_id to book_tags \n",
    "book_tags = book_tags.merge(books_cleaned[['book_id','goodreads_book_id']],on='goodreads_book_id')\n",
    "\n",
    "# remove punctuation from tags\n",
    "punctuation = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ '\n",
    "\n",
    "# standardize letters to lowercase letters, replace all punctuation with spaces, trim white spaces\n",
    "tags[\"tag_name\"] = tags['tag_name'].str.replace('[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ ]',' ').map(lambda x: x.lower().strip())\n",
    "\n",
    "# merge tags and book_tags\n",
    "book_tags_cleaned = book_tags.merge(tags, on=['tag_id'])\n",
    "# filter top 20 tags for each book\n",
    "book_tags_cleaned = book_tags_cleaned.groupby(['book_id']).head(30)\n",
    "# Add column: collection of tags associated with each book\n",
    "book_tags_cleaned['tags'] = book_tags_cleaned.groupby(['book_id'])['tag_name'].transform(lambda x: ' '.join(x))\n",
    "# drop duplicates\n",
    "book_tags_cleaned = book_tags_cleaned[['book_id','tags']].drop_duplicates()\n",
    "# Add column: book title\n",
    "book_tags_cleaned = book_tags_cleaned.merge(books_cleaned[['book_id','title']],on=['book_id'])\n",
    "# test\n",
    "display(book_tags_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here are the most popular tags.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "stopwords = set(STOPWORDS) \n",
    "\n",
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = stopwords, \n",
    "                min_font_size = 10).generate(' '.join(book_tags_cleaned['tags']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the most popular tags are 'currently-reading' and 'favorites currently' which are applicable to numerous books. We can also see that the most popular genres include 'fiction', 'adult fiction', 'sci fi', fantasy', and 'children'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 *ratings*\n",
    "\n",
    "***ratings*** contains all the ratings given from any user. \n",
    "\n",
    "- Include only the last rating a user gave to a book since some books were rated multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_cleaned = ratings.groupby(by=['user_id', 'book_id']).last().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there are a large number of users and books, the vast majority of people have only rated a few number of books. In an effort to reduce space we will filter out the majority of ratings. Let's look at the ***ratings*** statistics for all the users in the system and compare the information to a random 30%* of the population and also the top 30%* of users who have given the most ratings. \n",
    "\n",
    "\n",
    "*These percentages were chosen arbitrarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all users\n",
    "all_ratings_count = ratings_cleaned.groupby('user_id').agg('count')[['book_id']].rename(columns={'book_id': 'all_users_rating'})\n",
    "display(all_ratings_count.describe())\n",
    "\n",
    "# random 30%\n",
    "thirty_users = ratings_cleaned.groupby('user_id').agg('count').reset_index().sample(frac=.3,random_state=42)['user_id']\n",
    "ratings_30 = ratings_cleaned[ratings_cleaned['user_id'].isin(thirty_users)]\n",
    "num_ratings_per_30_user = ratings_30.groupby('user_id').agg('count')[['book_id']].rename(columns={'book_id': 'random_users_rating'})\n",
    "display(num_ratings_per_30_user.describe())\n",
    "\n",
    "# top 30% of users who have most ratings\n",
    "all_users_ordered = ratings_cleaned.groupby('user_id').agg('count').reset_index().sort_values('book_id',ascending=False)\n",
    "top_users = all_users_ordered.head(int(len(all_users_ordered)*.30))['user_id']\n",
    "ratings_top_users = ratings_cleaned[ratings_cleaned['user_id'].isin(top_users)].merge(books_cleaned[['title','book_id']], on='book_id',how='left')\n",
    "num_ratings_per_top_user = ratings_top_users.groupby('user_id').agg('count')[['book_id']].rename(columns={'book_id': 'top_users_rating'})\n",
    "\n",
    "display(num_ratings_per_top_user.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count for each table represents the number of users taken into consideration. The first table includes all ratings accounted for from 53424 users. The second table includes a random 30% of ratings from 16027 users. The third table includes the top 30% of users who rated the most books and there are also 16027 users.\n",
    "\n",
    "\n",
    "**How many ratings does each person tend to give?**\n",
    "\n",
    "As you can see, the mean number of ratings each person gives is about 18. This is true for the entire population and the random subset. But, the top 25% of users who give the most ratings has an average of 52 ratings per user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_count = ratings_cleaned.groupby('rating').agg('count').reset_index()[['rating','book_id']]\n",
    "ratings_count = ratings_count.rename(columns={'book_id': 'all_percentage'})\n",
    "\n",
    "ratings_top_users_count = ratings_top_users.groupby('rating').agg('count').reset_index()[['rating','book_id']]\n",
    "ratings_top_users_count = ratings_top_users_count.rename(columns={'book_id': 'top_percentage'})\n",
    "\n",
    "ratings_30_count = ratings_30.groupby('rating').agg('count').reset_index()[['rating','book_id']]\n",
    "ratings_30_count = ratings_30_count.rename(columns={'book_id': 'random_percentage'})\n",
    "\n",
    "combined_ratings = pd.merge(pd.merge(ratings_count,ratings_top_users_count,on='rating'),ratings_30_count,on='rating').set_index('rating')\n",
    "\n",
    "combined_ratings_percentage = (100. * combined_ratings / combined_ratings.sum())\n",
    "\n",
    "combined_ratings.loc['Column_Total']= combined_ratings.sum(numeric_only=True, axis=0)\n",
    "combined_ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(combined_ratings_percentage)\n",
    "\n",
    "combined_ratings_percentage.reset_index().plot(x=\"rating\", y=[\"all_percentage\", \"top_percentage\", \"random_percentage\"], kind=\"bar\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table represents the distribution of ratings (from 1-5) for all of our samples. For example, approximately 1.99% of all users gave a rating of 1 to a book. In comparison, 1.96% of our random subset of 30% gave a rating of 1 and 1.94% of the top 30% of users gave a rating of 1.\n",
    "\n",
    "\n",
    "**In general, do users who rate more often rate differently from those who don't?**\n",
    "\n",
    "No. The distribution of ratings is almost the same for all three samples. These users do not behave differently from the rest of the population. So, in an effort to save space but still maintain the best results, we will choose the 30% subset to represent the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_cleaned = ratings_top_users\n",
    "ratings_cleaned.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is there a relationship between the year a book was published and the average rating it got?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.regplot(data=books_cleaned, x=\"work_ratings_count\", y=\"average_rating\")\n",
    "ax.set(xlabel='Number of Ratings', ylabel='Average Rating', title='Year Published vs. Number of Ratings of a Book')\n",
    "plt.show(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a positive correlation between the number of ratings and average rating. Books that are very popular seem to have a higher average rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is there a relationship between the year a book was published and the number of ratings it got?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_year_avg_ratings = books_cleaned.groupby('original_publication_year').agg(sum).reset_index()[['original_publication_year','work_ratings_count']]\n",
    "ax = sns.scatterplot(data=books_year_avg_ratings, x=\"original_publication_year\", y=\"work_ratings_count\")\n",
    "ax.set(xlabel='Year', ylabel='Number of Ratings', title='Year Published vs. Number of Ratings of a Book')\n",
    "plt.show(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Books that were published closer to the present year received an overwhelmingly large portion of total ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is there a relationship between the book title length and the number of ratings it received?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_cleaned['title_length']  = books_cleaned['title'].str.len()\n",
    "ax = sns.scatterplot(data=books_cleaned, x=\"title_length\", y=\"work_ratings_count\")\n",
    "ax.set(xlabel='Title Length', ylabel='Number of Ratings', title='Is there a Relationship Between Title Length and Number of Ratings?')\n",
    "plt.show(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **4. Popularity-Based Filtering**\n",
    "\n",
    "### 4.1 Description\n",
    "\n",
    "Popularity Based Filtering is a recommendation system that suggests the most \"popular\" items. User preferences are not taken into account; instead, recommendations are based on a ranking or score that utilizes item attributes (i.e. watch time, ratings, number of purchases). It is important to note that this algorithm recommends the same content to every consumer. Some examples of this type of system include the Youtube Trending and Twitter News.\n",
    "\n",
    "### 4.2 Pros and Cons\n",
    "\n",
    "#### Pros:\n",
    " - Fixes cold start issues: If a user is a new user who has limited to no history, recommending trending products (as opposed to a random assortment) increases the chance of the user clicking on or purchasing products.\n",
    " \n",
    "- Easy to code: Doesn't require complex algorithms to implement. \n",
    "\n",
    "#### Cons:\n",
    " - Not Personalized: Every user is being offered the same products. This method takes no consideration  what the customer's tastes and preferences are.\n",
    "\n",
    "### 4.3 Methodology\n",
    "   For this project, popularity is based on a weighted ranking formula that considers a book's average rating, total number of votes, mean rating across the dataset, and minimum number of votes for the book to be listed in the top 10% of books. Books with a high rating but small number of reviews are ranked lower than books with a slighly lower rating but large number of reviews. Likewise, books with a low rating but high number of reviews are ranked higher than books with a slightly higher rating but low number of reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Ranking Formula\n",
    "This is the formula we will use to determine which books are the most \"popular\".\n",
    "\n",
    "\n",
    "$$ W = \\frac{Rv + Cm}{v + m} $$\n",
    "where:\n",
    "\n",
    "W: Weighted Ranking for particular book\n",
    "\n",
    "R: Average rating (out of 5) for book\n",
    "\n",
    "v: Number of votes for book\n",
    "\n",
    "C: Mean vote across dataset\n",
    "\n",
    "m: Minimum number of votes for book to be listed in the 10% books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute weighted ranking scores for each book\n",
    "\n",
    "r = books_cleaned['average_rating'] # average rating per book\n",
    "v = books_cleaned['work_ratings_count'] # number of ratings per book\n",
    "c = books_cleaned['average_rating'].mean() # average rating across entire dataset\n",
    "m = books_cleaned['work_ratings_count'].quantile(.90) # top 10% of books with the most ratings\n",
    "\n",
    "books_weighted_ranking = books_cleaned[['book_id','title','average_rating','work_ratings_count']].copy()\n",
    "books_weighted_ranking['weighted_score'] = (r*v + c*m) / (v+m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_weighted_ranking[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table that sorts books based on ranking\n",
    "books_weighted_ranking = books_weighted_ranking.sort_values(by=['weighted_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that returns most popular books\n",
    "\n",
    "def popular_rec(num_books):\n",
    "    return books_weighted_ranking[['title']][0:num_books]\n",
    "popular_rec(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plots top 10 most popular books\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "most_popular_books = books_weighted_ranking[0:10]\n",
    "ax.barh(most_popular_books['title'],most_popular_books['weighted_score'],align='center')\n",
    "ax.set_xlabel('Weighted Score')\n",
    "ax.set_ylabel('Book Title')\n",
    "ax.set_title('Most Popular Books')\n",
    "ax.invert_yaxis() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Content-Based Filtering\n",
    "\n",
    "\n",
    "### 5.1 Description\n",
    "This method recommends products similar to what the user has purchased/clicked on. Examples include recommending Apple products when purchasing an iPhone case online or recommending books from authors with similar writing style. Item attributes (i.e. keywords, description, author, genre, etc.) are utilized to recommend products similar to what the user has purchased/used/clicked on in the past. \n",
    "\n",
    "\n",
    "### 5.2 Pros and Cons\n",
    "\n",
    "#### Pros:\n",
    "- Does not suffer from a cold start: Even if a new user has never purchased a product before, if their profile contains genres they are interested in, content-based filtering will still be useful to implement\n",
    "\n",
    "#### Cons:\n",
    "- Item attributes are key: If there is not a good amount of item data, then this method will not be as good of a predictor\n",
    "- The model can only make recommendations based on existing interests of the user. In other words, the model has limited ability to expand on the users' existing interests.\n",
    "\n",
    "### 5.3 Methodology\n",
    "\n",
    "The feature used in this section is tags. The tags table consists of 34253 possible unique tags that can be assigned to a book. The book_tags table lists out the top 100 tags associated with each book and their count. Only the top 30 tags (based on count) for each book will be accounted for.\n",
    "\n",
    "TfidfVectorizer (Term Frequency and Inverse Document Frequency Vectorizor) and cosine_similarity are used to compute similarity scores for each book.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 TFIDFVectorizor\n",
    "\n",
    "TfidfVectorizer determines how relevant a word is to the given book's tag list within the entire tag list for each book. In order to compute the TF-IDF value (for each word-book combination), two metrics are multiplied toegether: (1) how often a word occurs in a tag-list and (2) the inverse document frequency of the word across the entire collection of tag lists.\n",
    "\n",
    "The TFIDF value increases proportionally to the number of times a word appears in the tag list for the book in question. The TFIDF value decreases when a word is commonly found in other tag lists, alluding to the conclusion that the word is not important to that book in particular.\n",
    "\n",
    "#### **Term Frequency**\n",
    "The higher the term frequency, the more times the word is found in that specific tag list. The lower the term frequency, the less times the word is found in that specific tag list. \n",
    "$$ TF = \\frac{a}{b} $$\n",
    "where:\n",
    "\n",
    "TF = Term Frequency\n",
    "\n",
    "a = Number of times word is included in the tag list\n",
    "\n",
    "b = Number of words in tag list (could be more than 30 if a tag is comprised of more than one word)\n",
    "\n",
    "#### **Inverse Document Frequency**\n",
    "Measures how common or rare a word is across every tag list. The closer this value is to 0, the more common a word is; the closer this value is to 1, the less common a word is.\n",
    "$$ IDF = log(\\frac{c}{d})$$\n",
    "where:\n",
    "\n",
    "IDF = Inverse Document Frequency (IDF)\n",
    "\n",
    "c = Number of books\n",
    "\n",
    "d = Number of books containing specific word\n",
    "\n",
    "#### TF-IDF Score\n",
    "The higher the score, the more descriptive the word is for that specific book. The lower the score, the less descriptive the word is for that specific book. Although some tags were prevalent in all genres of books, the cool thing about TF-IDF is that it won't rely heavily on those popular words to determine how similar books are. The more popular a tag is, the less descriptive it is to an individual book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(analyzer='word',stop_words='english',strip_accents='unicode',ngram_range=(1,2))\n",
    "# ,ngram_range=(1,3) reduced from 13681 to 391\n",
    "tfv_matrix = tfv.fit_transform(book_tags_cleaned['tags'])\n",
    "tfv_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 10,000 books and 3865 unique tags. Here is what the string of tags looks like for some of the books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_tags_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6 Cosine Similarity\n",
    "\n",
    "Now that we are able to numerically represent a book through its tags, we need to figure out how similar each book is to one another. We do this by calculating their cosine similarity. \n",
    "\n",
    "Mathematically, Cosine similarity is a metric that measures the cosine of the angle between two vectors projected in a multi-dimensional space. In our case, each vector represents all of the TF-IDF scores of each word for a given book. The cosine similarity score between two books measures how similar they are to each other. \n",
    "\n",
    "#### Why cosine distance?\n",
    "The cosine simiilarity takes into account the direction of the books and not the magnitude. Even if one book is better described as \"action\" than another, despite both having a low \"romance\" score, our algorithm should still recommend both books to the user if they prefer action. These two points have a large Euclidean distance, but their cosine distance is relatively small, so they are deemed more similar.  \n",
    "\n",
    "Let's say the TF-IDF score for the word \"comedy\" for book A is 5 and the score for book B is 4. This means that book A is slightly more comedic than book B. If user 1 has read book A, then the recommendation system has a high chance of recommending book B. Let's say book C has a comedy score of 1, then the recommendation system will not recommend book C to user 1.\n",
    "\n",
    "![](https://miro.medium.com/max/500/1*tJ12OM8W4WX2J5Lu1J2EMg.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://dh2016.adho.org/abstracts/static/data/290/10000201000007AF000007CFCCC81279FE2EA7FD.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn.metrics.pairwise cosine_similarity\n",
    "\n",
    "cosine_similarity looks at the TFIDF vector for each word for each book and gives a score between 0 and 1 to every combination of books. The closer the cosine_similarity score is to 1, the more similar those pair of books are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Computing the cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(tfv_matrix, tfv_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(book_tags_cleaned.index,index=book_tags_cleaned['title'])\n",
    "\n",
    "def content_based_rec(title,sig=cosine_sim):\n",
    "    book_index = indices[title]\n",
    "    sorted_scores = sorted(list(enumerate(sig[indices[book_index]])),key=lambda x: x[1],reverse=True)[1:11]\n",
    "    return book_tags_cleaned.iloc[[i[0] for i in sorted_scores],2]                  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test out the content-based filtering method on these books. The top book recommended is the most similar to the book given in terms of tags and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_rec('Ella Enchanted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_rec('Harry Potter and the Half-Blood Prince (Harry Potter, #6)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Collaborative Filtering\n",
    "\n",
    "\n",
    "### 5.1 Description\n",
    "\n",
    "Collaborative Filtering is built on the idea that people prefer things that are similar to things they already like as well as things that people similar to them like.\n",
    "\n",
    "#### Collaborative Filtering can be approached in two different ways:####\n",
    "\n",
    "Memory Based and Model Based. Here is a figure showing their differences. We will better understand their differences throughout the rest of this kernel.\n",
    "\n",
    "![](https://miro.medium.com/max/800/1*7uW5hLXztSu_FOmZOWpB6g.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go any further, let's look at the sparsity of our data. Although we have gathered the top 30% of raters in our *ratings_cleaned* table, there are still many books not rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print total number of users and total books we are looking at\n",
    "num_users = ratings_cleaned.user_id.unique().shape[0]\n",
    "num_books = ratings_cleaned.book_id.unique().shape[0]\n",
    "print(\"Total Users: \" + str(\n",
    "    num_users) + \" | Total Books: \" + str(num_books))\n",
    "\n",
    "# sparsity of data\n",
    "sparsity = round(1.0-len(ratings_cleaned)/float(num_users*num_books),3)\n",
    "print(\"Sparsity: \" + str(sparsity*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh-oh. It seems that one book hasn't been rated by any of the top 30% of users. Let's figure out which book it is. Then, we will create a pivot table of user_ids and book_ids with their ratings as the values. Then, we will insert our missing book_id in and replace the missing values with 0. This table will be essential to our system going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ratings to pivot table and fills nan with 0\n",
    "pivot_ratings = ratings_cleaned.pivot(index='user_id', columns='book_id', values='rating')\n",
    "pivot_ratings = pivot_ratings.fillna(0)#.apply(lambda row: row.fillna(0)\n",
    "\n",
    "# check which books were not rated and add them in as a column of 0s\n",
    "# book_id_not = []\n",
    "# book_id_possible = np.arange(1,10001)\n",
    "\n",
    "# for i in book_id_possible:\n",
    "#     if i not in ratings_cleaned['book_id'].unique():\n",
    "#         book_id_not.append(i)\n",
    "\n",
    "# display(book_id_not)\n",
    "#master_table.insert(loc=8616, column=8616, value=0)\n",
    "pivot_ratings.insert(loc=8882, column=8882, value=0)\n",
    "\n",
    "pivot_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Memory Based Approach: \n",
    "This approach can further be divided into two sections.\n",
    "\n",
    "\n",
    "## **Item-Based Collaborative Filtering:** \n",
    "\n",
    "Recommends items similar to items the user already likes. There are two steps to this approach. \n",
    "1. Find the similarity scores between items the user likes and all other items\n",
    "2. Recommend items most similar to those items\n",
    "\n",
    "*“Users who liked this item also liked …”*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will find the cosine similarities for each book based on how users rated using K Nearest Neighbors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_ratings_knn = csr_matrix(pivot_ratings.T.values)\n",
    "knn = NearestNeighbors(metric='cosine',algorithm='brute')\n",
    "knn.fit(pivot_ratings_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if our matrix makes sense by using an example book. 'Twilight (Twilight, #1)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert book name to book_id\n",
    "book_id = books_cleaned[books_cleaned['title']=='Twilight (Twilight, #1)']['book_id'].values[0]\n",
    "# find the 10 most similar books based on cosine similarity\n",
    "book_distances, book_indices = knn.kneighbors(pivot_ratings.T.loc[book_id,:].values.reshape(1,-1),n_neighbors=10)\n",
    "\n",
    "display(book_distances)\n",
    "book_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the book_distances points to their respective book_indices. The book_id for 'Twilight (Twilight, #1)' is 2, so the cosine distance between them is 0; this makes sense. We only captured the top 10 most similar books. Now, let's recommend them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(book_distances.flatten())):\n",
    "        if i ==0:\n",
    "            print('Books similar to book {0}:\\n'.format('Twilight (Twilight, #1)')) #item_master_table.index[user_id]\n",
    "        else:\n",
    "            print('{0}: {1}, with distance of {2}'.format(i,books_cleaned[books_cleaned['book_id']==(book_indices.flatten()[i]+1)]['title'].values[0], book_distances.flatten()[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! Now we make it into a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_item_cf(book_title, num_books):\n",
    "    # gets top 9 similar books and similarity score\n",
    "    # converts book title to book_id\n",
    "    book_id = books_cleaned[books_cleaned['title']==book_title]['book_id'].values\n",
    "    book_distances,book_indices = knn.kneighbors(pivot_ratings.T.loc[book_id,:].values.reshape(1,-1),n_neighbors=num_books+1)\n",
    "    for i in range(0,len(book_distances.flatten())):\n",
    "        if i ==0:\n",
    "            print('')\n",
    "            print('Books similar to book {0}:\\n'.format(book_title))\n",
    "        else:\n",
    "            print('{0}: {1}, with distance of {2}'.format(i,books_cleaned[books_cleaned['book_id']==(book_indices.flatten()[i]+1)]['title'].values[0],book_distances.flatten()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_cf('Twilight (Twilight, #1)', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's bring it up a notch and recommend a given user books that are similar to each of their top rated books. We will let the user customize how many books they want recommended to them and a rating threshold so that only books that are similar to books they rated at or above the threshold are recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_cf(user_id, threshold_rating, num_books):\n",
    "    find_books_similar_to = ratings_cleaned[(ratings_cleaned['user_id'] == user_id) & (ratings_cleaned['rating'] >= threshold_rating)]['title'].array\n",
    "    for book in find_books_similar_to:\n",
    "        item_item_cf(book, num_books)\n",
    "    print('i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_based_cf(7,5,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the recommended books for user 7 who only wants 2 books most similar to books user 7 has rated 5 stars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **User-Based Collaborative Filtering:** \n",
    "\n",
    "Recommends items that are liked by similar people.\n",
    "\n",
    "1. Score every person in the system using a comparison method such as cosine similarity or pearson correlation\n",
    "2. Recommend products that are rated well by similar persons using a weighted sum or linear regression\n",
    "\n",
    "“Users similar to you also liked …”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the process by looking at a sample user, user 19. Here are the books they rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_cleaned[ratings_cleaned['user_id']==19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to item-based collaborative filtering, we will use the cosine distances to figure out similarity. But instead of finding similar items, we will find similar users so we transpose the user-book matrix. Then, we will use k nearest neighbors to figure out which users have the shortest distances to each other, aka which 30 users are the most similar to user 19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_cleaned[ratings_cleaned['user_id']==19]\n",
    "pivot_ratings_knn = csr_matrix(pivot_ratings.values)\n",
    "knn = NearestNeighbors(metric='cosine',algorithm='brute')\n",
    "knn.fit(pivot_ratings_knn)\n",
    "\n",
    "user_distances,user_indices = knn.kneighbors(pivot_ratings.loc[19,:].values.reshape(1,-1),n_neighbors=30)\n",
    "similar_users = pivot_ratings.index[user_indices.flatten()]\n",
    "\n",
    "for i in range(0,10):\n",
    "    if i ==0:\n",
    "            # if user is user given\n",
    "        print('Users similar to user {0}:\\n'.format('19')) #master_table.index[user_id]\n",
    "    else:\n",
    "            # else print top 9 users \n",
    "            # gets location top users and prints their user_id\n",
    "        print('{0}: {1}, with distance of {2}'.format(i,pivot_ratings.index[user_indices.flatten()[i]],user_distances.flatten()[i]))\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the formula we will be using to recommend books we think user19 will rate highly.\n",
    "\n",
    "\n",
    "![](https://miro.medium.com/max/686/1*cUqdJH0ppY9yCvMrah-ylA.png)\n",
    "\n",
    "where:\n",
    "\n",
    "$s(u,i)$ represents the predicted score\n",
    "\n",
    "$u$ represents the user given (user19)\n",
    "\n",
    "$i$ represents a given book\n",
    "\n",
    "$r$ represents the rating \n",
    "\n",
    "$V$ represents all similar users\n",
    "\n",
    "$\\bar{r}_{u}$ represents the user's (user 19) mean rating\n",
    "\n",
    "${r}_{vi}$ represents the rating given by an individual user to a specific book\n",
    "\n",
    "$\\bar{r}_{v}$ represents the mean rating of a specific book\n",
    "\n",
    "$w_{uv}$ represents the weight given (similarity score) between the user $u$ and user $v$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_based_cf_df = ratings_cleaned.groupby('user_id').agg(np.mean).drop(['book_id'],axis=1)\n",
    "\n",
    "user_based_cf_df = ratings_cleaned.merge(user_based_cf_df, how='inner',on='user_id')\n",
    "user_based_cf_df['mean_difference'] = user_based_cf_df['rating_x'] - user_based_cf_df['rating_y']\n",
    "user_based_cf_df\n",
    "\n",
    "# rating_x : rating given by user_id to book_id\n",
    "# rating_y : average rating of user_id\n",
    "# mean_difference: rating_x - rating_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matrix represents ${r}_{vi} -\\bar{r}_{v}$ in our equation \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_mean_difference = pd.pivot_table(user_based_cf_df,values='mean_difference',index='user_id',columns='book_id')\n",
    "pivot_mean_difference = pivot_mean_difference.fillna(0) #user_master_table.mean(axis=0))\n",
    "pivot_mean_difference.insert(loc=8882, column=8882, value=0)\n",
    "pivot_mean_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will multiply each cell by $w_{uv}$ and divide by $\\sum_{v\\in V}{w_{uv}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_scores = sum(1 - user_distances.flatten()) # denominator\n",
    "similarity_scores_T = 1-user_distances.T # similarity scores for each user\n",
    "# putting the equation together\n",
    "pivot_mean_difference = pivot_mean_difference.loc[similar_users,:].multiply(similarity_scores_T/similarity_scores, axis=0)\n",
    "# entire fraction summation\n",
    "pivot_mean_difference.loc['Column_Total'] = pivot_mean_difference.sum(axis=0) \n",
    "\n",
    "# user 19's average rating\n",
    "u_avg_rating = ratings_cleaned.groupby('user_id').agg(np.mean).loc[19,'rating']# 3.2083333333333335\n",
    "\n",
    "# adding user 19's average rating to each user-book pair score and sorting them from highest to lowest\n",
    "recs = sorted(list(enumerate(pivot_mean_difference.loc['Column_Total'] + u_avg_rating, 1)),key=lambda x: x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hurray! We found the best books we think the user will rate highly. Now, let's verify to make sure these numbers are correct by looking at the first few books. A high and positive mean difference verifies that similar users liked the book, so they should be recommended to user 19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list into dataframe only showing top 10 books\n",
    "predicted_books = pd.DataFrame(recs,columns=['book_id','predicted_rating'])[:10]\n",
    "display(predicted_books.head())\n",
    "\n",
    "\n",
    "# dataframe showing how similar users rated the books recommended\n",
    "display(user_based_cf_df[(user_based_cf_df['user_id'].isin(similar_users)) & (user_based_cf_df['book_id'].isin(predicted_books['book_id']))].sort_values('book_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_books['book_id'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's put it all into a function and verify it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_based_cf(user_id,k_neighbors, n_books):\n",
    "    '''\n",
    "        Finds the closest neighbors (k_neighbors) in terms of cosine similarity for a given user (user_id) and\n",
    "        Returns the top books (n_books) the model predicts the user will rate highly \n",
    "        \n",
    "    '''\n",
    "\n",
    "    user_distances,user_indices = knn.kneighbors(pivot_ratings.loc[user_id,:].values.reshape(1,-1),n_neighbors=k_neighbors)\n",
    "    similar_users = pivot_ratings.index[user_indices.flatten()]\n",
    "\n",
    "    for i in range(0,len(user_distances.flatten())):\n",
    "        if i ==0:\n",
    "                # if user is user given\n",
    "            print('Users similar to user {0}:\\n'.format(user_id)) #master_table.index[user_id]\n",
    "        else:\n",
    "                # else print top 9 users \n",
    "                # gets location top users and prints their user_id\n",
    "            print('{0}: {1}, with distance of {2}'.format(i,pivot_ratings.index[user_indices.flatten()[i]],user_distances.flatten()[i]))\n",
    "\n",
    "    user_based_cf_df = ratings_cleaned.groupby('user_id').agg(np.mean).drop(['book_id'],axis=1)\n",
    "    user_based_cf_df = user_based_cf_df.merge(ratings_cleaned, how='inner',on='user_id')\n",
    "    user_based_cf_df['mean_difference'] = user_based_cf_df['rating_x'] - user_based_cf_df['rating_y']\n",
    "\n",
    "    similarity_scores = sum(1 - user_distances.flatten()) # denominator\n",
    "    similarity_scores_T = 1-user_distances.T # similarity scores for each user\n",
    "    # putting the equation together\n",
    "    pivot_mean_difference_func = pivot_mean_difference.loc[similar_users,:].multiply(similarity_scores_T/similarity_scores, axis=0)\n",
    "    # entire fraction summation\n",
    "    pivot_mean_difference_func.loc['Column_Total'] = pivot_mean_difference_func.sum(axis=0) \n",
    "\n",
    "    # user's average rating\n",
    "    u_avg_rating = ratings_cleaned.groupby('user_id').agg(np.mean).loc[user_id,'rating']# 3.2083333333333335\n",
    "\n",
    "    # adding user's average rating to each user-book pair score and sorting them from highest to lowest\n",
    "    recs = sorted(list(enumerate(pivot_mean_difference_func.loc['Column_Total'] + u_avg_rating, 1)),key=lambda x: x[1],reverse=True)\n",
    "    # recs in a dataframe\n",
    "    recs_df = pd.DataFrame(recs,columns=['book_id','predicted_rating'])[:n_books]\n",
    "    \n",
    "    for i in range(0,len(recs_df)):\n",
    "        if i ==0:\n",
    "                # if user is user given\n",
    "            print('')\n",
    "            print('Top {0} Books liked by {0} people most similar to user 19:\\n'.format(n_books, k_neighbors)) #master_table.index[user_id]\n",
    "        else:\n",
    "                # else print top 9 users \n",
    "                # gets location top users and prints their user_id\n",
    "            print('{0}: {1}, with your predicted rating of {2}'.format(i,recs_df['book_id'][i],recs_df['predicted_rating'][i]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_based_cf(19,30,10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Why use user-based collaborative filtering over item-based collaborative filtering?\n",
    "\n",
    "- In practice, user-based CF does a lot better in performance in comparison to item-based CF. This is true especially when there is a large amount of data because finding similar people is easier in comparison to a small dataset. Overall, a large training dataset leads to better recommendations. Additionally, the amount of testing data does not need to be needlessly big to achieve a decent outcome.\n",
    "\n",
    "### Why use item-based collaborative filtering over user-based collaborative filtering?¶\n",
    "\n",
    "- First, the system may perform poorly when there are far more items than ratings. This is also known as a cold start, where the user is new and has not yet engaged with the system enough (through purchases, ratings, clicks, etc.) for the model to find people with similar tastes. This terminology can also be expanded to the whole system in which everyone is new and the whole system fails to provide optimal recommendations using item-based CF.\n",
    "- In general, there are usually much less items than people, so a 2d matrix mapping similar items will be much smaller than a 2d matrix mapping similar people. This decrease in space makes computing similarity scores much faster and takes up less resources to store.\n",
    "- Another reason user-based collaborative filtering is used is because user tastes may change, so what they may have liked before will not be beneficial to predicting what they will like now or in the future. Items are more static than individuals - a student may take a statistics course in the fall one semester and purchase statistics textbooks, but may take economics in the spring and not want statistics books to be recommended. On the other hand, a statistics textbook will always stay a statistics textbook. People's tastes will almost always change throughout the duration of their lifetime, so their similarity scores with other people will always be changing.\n",
    "\n",
    "\n",
    "## Memory Based Collaborative Filtering Pros and Cons\n",
    "\n",
    "#### Pros\n",
    "- Easy toimplement.\n",
    "- More accurate than content-based filtering.\n",
    "\n",
    "#### Cons\n",
    "- Sparsity in data. When the percentage of pele who rate items is low, this method is less accurate and predictive of what people will like and dislike. This is especially true for users who are new (cold start) and have not yet rated enough items for the system to be optimal. Similarly, if there is only one person who has rated two items and liked them both, then the model thinks these items are similar.\n",
    "- Scalability. The more people there are in the system, the more memory and space are needed to compute the nearest neighbors.\n",
    "\n",
    "\n",
    "## 2. Model Based Approach:\n",
    "\n",
    "Model-based Collaborative Filtering is based on matrix factorization (MF) which is an unsupervised learning approach that seeks to find underlying variables known as latent factors to predict the unknown ratings. In our case, we will use Single Value Decomposition (SVD).\n",
    "\n",
    "**How does SVD work?**\n",
    "\n",
    "When the user-item matrix is sparse in relation to its size, use SVD to represent the matrix in two lower ranking matrices. The first matrix has rows containing users and columns representing latent factors that are unknown to you but capture the preferences of the users. These factors could represent how much the user likes comedy, how much the length of the book comes in to play, etc. The second matrix contains rows of the latent features and the columns which represent the book. Similarly, the latent feature represents how comedic a book is, the length of the book, etc. When multiplied, these matrices impute missing entries in the original matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we split our ratings data into two sets: train and set. Unlike cosine similarity, magnitude matters for SVD so we have to normalize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% trainset, 20% testset  \n",
    "shuffled = pivot_ratings.replace(0,np.NaN).sample(frac = 1,axis=0,random_state=42)\n",
    "threshold = int(.8 * len(shuffled))                                     \n",
    "train = shuffled[:threshold]                             \n",
    "test = shuffled[threshold:]\n",
    "train_indices = train.index.values\n",
    "test_indices = test.index.values\n",
    "\n",
    "# normalize ratings\n",
    "train_means = np.nan_to_num(np.mean(train,axis=1).values)\n",
    "train_demeaned = train.sub(train_means,axis=0).replace(np.NaN,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will test different numbers of latent features to see which one produces the lowest error in predicting ratings. Remember, latent features are 'hidden' features that help us produce the original matrix in a small space. We will test 10, 20, 50, and 100 features and see which produces the lowest error and compare their implementation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 10 SVD components from train matrix\n",
    "start10 = time.time()\n",
    "u,s,vt = svds(train_demeaned,k=10)\n",
    "s_diag_matrix=np.diag(s)\n",
    "X_pred = np.dot(np.dot(u, s_diag_matrix), vt)\n",
    "svd_10_rmse = mean_squared_error(X_pred,train_demeaned,squared=True)\n",
    "end10 = time.time()\n",
    "print('SVD Using 10 Features RMSE: ' + str(svd_10_rmse))\n",
    "print(end10 - start10)\n",
    "\n",
    "# get 20 SVD components from train matrix\n",
    "start20 = time.time()\n",
    "u,s,vt = svds(train_demeaned,k=20)\n",
    "s_diag_matrix=np.diag(s)\n",
    "X_pred = np.dot(np.dot(u, s_diag_matrix), vt)\n",
    "svd_20_rmse = mean_squared_error(X_pred,train_demeaned,squared=True)\n",
    "end20 = time.time()\n",
    "print('SVD Using 20 Features RMSE: ' + str(svd_20_rmse))\n",
    "print(end20 - start20)\n",
    "\n",
    "# get 50 SVD components from train matrix\n",
    "start50 = time.time()\n",
    "u,s,vt = svds(train_demeaned,k=50)\n",
    "s_diag_matrix=np.diag(s)\n",
    "X_pred = np.dot(np.dot(u, s_diag_matrix), vt)\n",
    "svd_50_rmse = mean_squared_error(X_pred,train_demeaned,squared=True)\n",
    "end50 = time.time()\n",
    "print('SVD Using 50 Features RMSE: ' + str(svd_50_rmse))\n",
    "print(end50 - start50)\n",
    "\n",
    "# get 100 SVD components from train matrix\n",
    "start100 = time.time()\n",
    "u,s,vt = svds(train_demeaned,k=100)\n",
    "s_diag_matrix=np.diag(s)\n",
    "X_pred = np.dot(np.dot(u, s_diag_matrix), vt)\n",
    "svd_100_rmse = mean_squared_error(X_pred,train_demeaned,squared=True)\n",
    "end100 = time.time()\n",
    "print('SVD Using 100 Features RMSE: ' + str(svd_100_rmse))\n",
    "print(end100 - start100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown, SVD using 100 features gave us the lowest RMSE, but the time it took was incredibly long. SVD with 10 features seems to suffice well with the lowest time. Let's also compare our RMSE with the weight based average predictions we computed before in Part 1 of the project just to see whether these RMSEs are indeed better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Weighted-Averages RMSE with SVD RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create user-book pivot table with weighted ratings as values\n",
    "pivot_weighted_ratings = books_weighted_ranking.merge(ratings_cleaned, how='inner',on='book_id').pivot(index='user_id', columns='book_id', values='weighted_score').fillna(0)\n",
    "# insert book that wasn't rated\n",
    "pivot_weighted_ratings.insert(loc=8882, column=8882, value=0)\n",
    "\n",
    "# split data\n",
    "# weighted trainset is the same as svd trainset\n",
    "weightedshuffled = pivot_weighted_ratings.loc[train_indices,:]\n",
    "start_weighted = time.time()\n",
    "weightedpopular_rmse = mean_squared_error(weightedshuffled,train_demeaned,squared=True)\n",
    "end_weighted = time.time()\n",
    "print(end_weighted - start_weighted)\n",
    "print('Weight-Based RMSE: ' + str(weightedpopular_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Weighted Average RMSE in comparison to SVD RMSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = [svd_10_rmse,svd_20_rmse,svd_50_rmse,svd_100_rmse, weightedpopular_rmse]\n",
    "models = ['Train SVD with 10 Features','Train SVD 20 Features','Train SVD 50 Features','Train SVD 100 Features', 'Train Weighted Average']\n",
    "plt.bar(models, rmse);\n",
    "plt.xticks(rotation=90);\n",
    "plt.ylabel('RMSE');\n",
    "plt.title('RMSE for Different Collaborative Filtering Models');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test SVD on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize ratings\n",
    "test_nan = np.nan_to_num(np.mean(test,axis=1).values)\n",
    "test_demeaned = test.sub(test_nan,axis=0).replace(np.NaN,0)\n",
    "\n",
    "\n",
    "# get 10 SVD components from train matrix\n",
    "starttest = time.time()\n",
    "u,s,vt = svds(test_demeaned,k=10)\n",
    "s_diag_matrix=np.diag(s)\n",
    "X_pred = np.dot(np.dot(u, s_diag_matrix), vt)\n",
    "test_svd_10_rmse = mean_squared_error(X_pred,test_demeaned,squared=True)\n",
    "endtest = time.time()\n",
    "print('Test RMSE Using 10 Features: ' + str(test_svd_10_rmse))\n",
    "print(endtest - starttest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Test SVD RMSE with other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = [test_svd_10_rmse,svd_10_rmse,svd_20_rmse,svd_50_rmse,svd_100_rmse, weightedpopular_rmse]\n",
    "models = ['Test SVD with 10 Features','Train SVD with 10 Features','Train SVD 20 Features','Train SVD 50 Features','Train SVD 100 Features', 'Train Weighted Average']\n",
    "plt.bar(models, rmse);\n",
    "plt.xticks(rotation=90);\n",
    "plt.ylabel('RMSE');\n",
    "plt.title('RMSE for Different Collaborative Filtering Models');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model on Entire Top Users Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE with Both Test and Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_ratings_nan = pivot_ratings.replace(0,np.NaN)\n",
    "\n",
    "\n",
    "# get means for each user\n",
    "user_means = np.nan_to_num(np.mean(pivot_ratings_nan,axis=1).values)\n",
    "# subtract means from dataset and replace not-yet-rated items with 0\n",
    "all_demeaned = pivot_ratings_nan.sub(user_means,axis=0).replace(np.NaN,0)\n",
    "\n",
    "# get 10 SVD components from train matrix\n",
    "start10 = time.time()\n",
    "u,s,vt = svds(all_demeaned,k=10)\n",
    "s_diag_matrix=np.diag(s)\n",
    "X_pred_all = np.dot(np.dot(u, s_diag_matrix), vt)\n",
    "all_svd_10_rmse = mean_squared_error(X_pred_all,all_demeaned,squared=True)\n",
    "end10 = time.time()\n",
    "all_svd_10_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting User Ratings with SVD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform features by scaling each feature from 1 to 5\n",
    "sc=MinMaxScaler(feature_range = (1,5))\n",
    "svd_mat = sc.fit_transform(X_pred_all.T + user_means)\n",
    "\n",
    "# convert scaled matrix to df\n",
    "svd_df = pd.DataFrame(svd_mat.T, columns=pivot_ratings_nan.columns,index=pivot_ratings_nan.index)\n",
    "svd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_rec(user_id,num_recs):\n",
    "    print('Books user {0} has highly rated read:'.format(user_id))\n",
    "    print(user_based_cf_df[(user_based_cf_df['user_id'] == user_id) & (user_based_cf_df['rating_x'] > 3)][['title', 'rating_x','rating_y']])\n",
    "   \n",
    "    # dataframe of all books and predicted scores, sorted\n",
    "    user_recs = pd.DataFrame(svd_df.loc[user_id].sort_values(ascending=False).reset_index()).rename(columns = {user_id : 'predicted_rating'})\n",
    "    # find books that user has already read\n",
    "    user_read = user_based_cf_df[user_based_cf_df['user_id'] == user_id]\n",
    "    # take away books the user has read\n",
    "    # df: book_id | predicted_rating | title\n",
    "    new_books = user_recs[~user_recs['book_id'].isin(user_read)][:num_recs].merge(ratings_cleaned[['book_id','title']],on='book_id',how='inner').drop_duplicates().reset_index()\n",
    "    new_books\n",
    "    \n",
    "    # recommend the top n books with their titles and predicted rating\n",
    "    print('')\n",
    "    print('Top {0} Books we think user {1} would rate the highest:\\n'.format(num_recs, user_id))\n",
    "\n",
    "    for i in range(0,len(new_books)):\n",
    "        print('{0}: {1}, with your predicted rating of {2}'.format(i+1,new_books['title'][i],new_books['predicted_rating'][i]))\n",
    "\n",
    "\n",
    "def predict_rating(user_id,book_title):\n",
    "    # we will use SVD with 10 features\n",
    "    book_id = books_cleaned[books_cleaned['title']==book_title]['book_id'].values\n",
    "    print('The predicted rating for user {0} for {1} is {2}'.format(user_id,book_title,svd_df.loc[user_id,book_id])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_rec(10560,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_rating(52414,'Harry Potter and the Half-Blood Prince (Harry Potter, #6)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD Pros and Cons\n",
    "\n",
    "### Pros\n",
    "- Model Based Collaborative Filtering systems have a high predictive power considering how little information it requires (sparse matrix).\n",
    "\n",
    "\n",
    "### Cons\n",
    "- Latent features are not interpretable; there is no context behind them as the only information given are user ratings.\n",
    "- Cold start. When an item is not yet rated or hasn't been rated by many users, the system is less likely to give weight to it and will not be recommended.\n",
    "\n",
    "Overall, the best approach would be to use a combination of different methods. A mix of collaborative and content-based filtering will produce the best predictive power in which both the preferences of the users and contents of the items are weighted.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
